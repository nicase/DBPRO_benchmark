{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from qdrant_client.http.models import PointStruct\n",
    "import numpy as np\n",
    "import random\n",
    "import time \n",
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: siftsmall_base.fvecs\n",
      "    The dimension of the vectors in the file is: 128\n",
      "    The final shape of the loaded dataset siftsmall_base.fvecs is (10000, 128).\n",
      "Loading file: siftsmall_query.fvecs\n",
      "    The dimension of the vectors in the file is: 128\n",
      "    The final shape of the loaded dataset siftsmall_query.fvecs is (100, 128).\n",
      " Loading file: siftsmall_groundtruth.ivecs\n",
      "    The dimension of the vectors in the file is: 100\n",
      "    The final shape of the loaded dataset is (100, 100).\n"
     ]
    }
   ],
   "source": [
    "qdrantClient = QdrantClient(host='localhost', port=6333)\n",
    "base_vectors = utils.read_fvecs(\"../../dataset/siftsmall/siftsmall_base.fvecs\")\n",
    "query_vectors = utils.read_fvecs(\"../../dataset/siftsmall/siftsmall_query.fvecs\")\n",
    "knn_groundtruth = utils.read_ivecs(\"../../dataset/siftsmall/siftsmall_groundtruth.ivecs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_size = 128\n",
    "collection_name = \"ann_collection\"\n",
    "\n",
    "qdrantClient.delete_collection(collection_name=collection_name)\n",
    "\n",
    "qdrantClient.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=vector_size, distance=Distance.EUCLID),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation_id=0 status=<UpdateStatus.COMPLETED: 'completed'>\n"
     ]
    }
   ],
   "source": [
    "base_vectors = pd.DataFrame({'vector': base_vectors.tolist()})\n",
    "batch_points = [PointStruct(id=i, vector=elem[\"vector\"]) for i, elem in base_vectors.iterrows()]\n",
    "\n",
    "operation_info = qdrantClient.upsert(\n",
    "    collection_name=collection_name,\n",
    "    wait=True,\n",
    "    points=batch_points\n",
    ")\n",
    "print(operation_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vectors = pd.DataFrame({'vector': query_vectors.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search function starting\n",
      "Search function took 3.1911091804504395 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f'Search function starting')\n",
    "start_time = time.time()\n",
    "\n",
    "result_ids = []\n",
    "for _,elem in query_vectors.iterrows():\n",
    "    vec = elem[\"vector\"]\n",
    "    search_result = qdrantClient.search(\n",
    "            collection_name=collection_name, \n",
    "            query_vector=vec,\n",
    "            score_threshold=500,\n",
    "            limit=10000 \n",
    "            )\n",
    "    result_ids.append([elem.id for elem in search_result])\n",
    "\n",
    "end_time = time.time()\n",
    "time_span = end_time - start_time\n",
    "print(f'Search function took {end_time - start_time} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = utils.range_truth(query_vectors, base_vectors, threshold=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(truth)\n",
    "# df['size'] = df.iloc[:, 0].apply(lambda x: len(x))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QPS = 31.3371\n",
      "Average recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "true_positives = 0\n",
    "n_classified = 0\n",
    "for i,elem in enumerate(result_ids):\n",
    "    true_positives_iter = len(np.intersect1d(truth[i], elem))\n",
    "    true_positives += true_positives_iter\n",
    "    n_classified += len(elem)\n",
    "\n",
    "print(f'QPS = {(len(query_vectors) / time_span):.4f}')\n",
    "print(f'Average recall: {true_positives/n_classified}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
